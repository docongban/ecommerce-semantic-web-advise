# main_llm.py
import os
import openai
import rdflib
from rdflib import Graph

# --- Khá»Ÿi táº¡o API Key ---
openai.api_key = os.getenv("OPENAI_API_KEY") or "sk-fm61aSE74f32oM5gu5g4w9Nl7lc999v8448Ctx2ZHa0b7RoQ"  # Thay báº±ng key tháº­t

# ÄÆ°á»ng dáº«n Ä‘áº¿n folder Data
data_folder = os.path.join(os.getcwd(), "Data")
# ÄÆ°á»ng dáº«n Ä‘áº¿n file ontology vÃ  data
ontology_file_path = os.path.join(data_folder, "ontology.ttl")
data_file_path = os.path.join(data_folder, "data.ttl")
# Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a file
if not os.path.exists(ontology_file_path):
    print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file ontology táº¡i {ontology_file_path}")
    exit()
if not os.path.exists(data_file_path):
    print(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y file data táº¡i {data_file_path}")
    exit()

# ----------------------
# Step 1: Load ontology + data
# ----------------------
def load_graph():
    g = Graph()
    g.parse(ontology_file_path, format="ttl")
    g.parse(data_file_path, format="ttl")
    return g

graph = load_graph()

# --- Agent: Generate SPARQL báº±ng LLM ---
def generate_sparql_with_llm(question: str) -> str:
    system_prompt = """
Báº¡n lÃ  má»™t trá»£ lÃ½ RDF chuyÃªn sinh truy váº¥n SPARQL.
Ontology sá»­ dá»¥ng namespace <http://example.org/ontology#>
DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c vÃ­ dá»¥:

VÃ­ dá»¥ 1:
CÃ¢u há»i: ID cá»§a danh má»¥c cÃ³ tÃªn Xiaomi lÃ  gÃ¬?
SPARQL:
PREFIX ex: <http://example.org/ontology#>
SELECT ?id WHERE {
  ?s a ex:Category ;
     ex:name ?name ;
     ex:id ?id .
  FILTER CONTAINS(LCASE(STR(?name)), "xiaomi")
}

Chá»‰ tráº£ vá» SPARQL truy váº¥n, khÃ´ng cÃ³ chÃº thÃ­ch, khÃ´ng cÃ³ giáº£i thÃ­ch.
HÃ£y viáº¿t SPARQL cho cÃ¢u há»i sau:
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": question}
    ]

    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",  # hoáº·c "gpt-3.5-turbo"
        messages=messages,
        temperature=0
    )

    # TrÃ­ch xuáº¥t truy váº¥n SPARQL
    content = response["choices"][0]["message"]["content"]
    sparql_code = content.strip()
    return sparql_code

# --- Agent: Execute SPARQL ---
def execute_sparql(graph: Graph, sparql: str):
    try:
        results = graph.query(sparql)
        return [str(row[0]) for row in results]
    except Exception as e:
        return [f"Lá»—i khi thá»±c thi SPARQL: {e}"]

# --- Agent: Táº¡o cÃ¢u tráº£ lá»i tá»± nhiÃªn ---
def synthesize_answer(question: str, results: list[str]) -> str:
    if not results:
        return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p."
    if len(results) == 1:
        return f"Káº¿t quáº£: {results[0]}"
    return "Káº¿t quáº£:\n" + "\n".join(results)

# --- Main ---
def main():
    print("ğŸ“¥ Há»i báº¥t ká»³ cÃ¢u há»i vá» sáº£n pháº©m, danh má»¥c,... (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t)")
    while True:
        question = input("â“ CÃ¢u há»i: ")
        if question.lower() == "exit":
            break

        sparql = generate_sparql_with_llm(question)
        print("\nğŸ“„ SPARQL sinh bá»Ÿi GPT:\n", sparql)

        results = execute_sparql(graph, sparql)
        answer = synthesize_answer(question, results)

        print("ğŸ’¬ Tráº£ lá»i:", answer)
        print("-" * 50)

if __name__ == "__main__":
    main()
